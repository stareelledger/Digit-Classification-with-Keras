{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Classification\n",
    "## Importing important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datasets\n",
    "#### these datasets are are loaded from keras module of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xtrain,ytrain),(xtest,ytest)=l=keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of a single dataset\n",
    "xtrain[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=xtrain/255\n",
    "X2=xtest/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x207f354f6c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image of a single dataset\n",
    "plt.imshow(X1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling the Neural Network with keras\n",
    "#### In this we first use 3 layered neural network-\n",
    "###### 1)layer 1- this function (\"keras.layers.Fallten()\") changes the give 2D dataset in 1D dataset or we cay say flattens the input.\n",
    "###### 2)layer 2- in this layer we have 25 units of neuron on which data trains\n",
    "###### layer 3- in this layer we use 10 neurons to have sparse categorical output(i.e output between(0-9) in the the give 10   \n",
    "######   neurons where the neuron having the largest is considered as answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model=keras.Sequential({\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(25,activation='sigmoid'),\n",
    "    keras.layers.Dense(10,activation='sigmoid')\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we use adam optimizer with default learning rate as it works expectedly\n",
    "#and use 'sparse_categorical_croosentropy' as explained\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: 0.7393 - acc: 0.8500\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.2839 - acc: 0.9244\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 9s 144us/sample - loss: 0.2277 - acc: 0.9364\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.1981 - acc: 0.9447\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.1778 - acc: 0.9495\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.1629 - acc: 0.9538\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.1508 - acc: 0.9574\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.1414 - acc: 0.9593\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.1330 - acc: 0.9621\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1264 - acc: 0.9632\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 0.1203 - acc: 0.9647\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 12s 192us/sample - loss: 0.1151 - acc: 0.9669\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 11s 176us/sample - loss: 0.1104 - acc: 0.9681\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 0.1060 - acc: 0.9695\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1021 - acc: 0.9703\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 0.0984 - acc: 0.9711\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0950 - acc: 0.9720\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0919 - acc: 0.9736\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0895 - acc: 0.9740\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0865 - acc: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x207f377e6c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model with 20 epochs \n",
    "model.fit(X1,ytrain,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9371510e-06, 1.2218952e-06, 5.3644180e-06, ..., 3.4724414e-01,\n",
       "        3.2782555e-06, 6.5863132e-06],\n",
       "       [8.3148479e-06, 2.0229816e-04, 4.9860179e-02, ..., 0.0000000e+00,\n",
       "        9.5367432e-07, 0.0000000e+00],\n",
       "       [1.1920929e-07, 4.5792332e-01, 9.7590685e-04, ..., 3.0466914e-04,\n",
       "        2.1263957e-04, 1.1801720e-05],\n",
       "       ...,\n",
       "       [5.9604645e-08, 0.0000000e+00, 3.5762787e-07, ..., 2.5480986e-04,\n",
       "        3.6597252e-05, 1.1949539e-03],\n",
       "       [5.9604645e-08, 2.0861626e-07, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        3.1256676e-04, 8.9406967e-08],\n",
       "       [1.1622906e-06, 9.8347664e-07, 4.2259693e-05, ..., 5.9604645e-08,\n",
       "        1.1920929e-07, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting the model\n",
    "y_p=model.predict(X2)\n",
    "y_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the model output into an understandable manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looping to take max value from each single output\n",
    "yp=[np.argmax(y_p[i]) for i in range(0,len(y_p))]\n",
    "yp=np.array(yp,dtype='int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(ytest)\n",
    "print(yp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and loss on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on test set: 0.038\n",
      "Accuracy on test set 0.962\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "for i in range(0,1000):\n",
    "    if(ytest[i]!=yp[i]):\n",
    "        k+=1\n",
    "print(\"loss on test set:\",k/1000)\n",
    "print(\"Accuracy on test set\",1-(k/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking any random input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting value of 666th(randomly taken) dataset : 7\n",
      "\n",
      "Image of 666th data set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x207f4c79e88>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Predicting value of 666th(randomly taken) dataset :\",ytest[666])\n",
    "print(\"\\nImage of 666th data set:\")\n",
    "plt.imshow(X2[666])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
